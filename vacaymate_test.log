2025-09-08 22:28:49,722 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:28:53,211 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:28:53,428 - __main__ - INFO - 
Test Input:
2025-09-08 22:28:53,428 - __main__ - INFO - - From: Barcelona
2025-09-08 22:28:53,428 - __main__ - INFO - - To: Paris
2025-09-08 22:28:53,429 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:28:53,429 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:28:53,429 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:29:02,993 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:29:04,159 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 58, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 242, in run_vacation_graph
    for chunk in graph.stream(initial_state):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\main.py", line 2647, in stream
    for _ in runner.tick(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 381, in researcher_node
    agent = create_tool_calling_agent(llm, tools, prompt)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\tool_calling_agent\base.py", line 94, in create_tool_calling_agent
    raise ValueError(msg)
ValueError: Prompt missing required variables: {'agent_scratchpad'}
During task with name 'researcher' and id '05f082f0-9e2a-4cc4-fba1-82d0690e97ef'

2025-09-08 22:29:13,643 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:29:16,514 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:29:16,515 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:29:16,519 - __main__ - INFO - 
Test Input:
2025-09-08 22:29:16,519 - __main__ - INFO - - From: Barcelona
2025-09-08 22:29:16,519 - __main__ - INFO - - To: Paris
2025-09-08 22:29:16,520 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:29:16,520 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:29:16,520 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:29:28,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:29:29,263 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 242, in run_vacation_graph
    for chunk in graph.stream(initial_state):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\main.py", line 2647, in stream
    for _ in runner.tick(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 381, in researcher_node
    agent = create_tool_calling_agent(llm, tools, prompt)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\tool_calling_agent\base.py", line 94, in create_tool_calling_agent
    raise ValueError(msg)
ValueError: Prompt missing required variables: {'agent_scratchpad'}
During task with name 'researcher' and id '976631a8-162a-4a61-b50e-548873974b44'

2025-09-08 22:30:32,825 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:30:36,081 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:30:36,081 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:30:36,088 - __main__ - INFO - 
Test Input:
2025-09-08 22:30:36,089 - __main__ - INFO - - From: Barcelona
2025-09-08 22:30:36,089 - __main__ - INFO - - To: Paris
2025-09-08 22:30:36,089 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:30:36,090 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:30:36,090 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:30:45,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:30:47,583 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:30:58,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-08 22:30:58,505 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 242, in run_vacation_graph
    for chunk in graph.stream(initial_state):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\main.py", line 2647, in stream
    for _ in runner.tick(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 415, in researcher_node
    result = agent_executor.invoke(agent_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 573, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 1044, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1131, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1256, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 175543 tokens (175422 in the messages, 121 in the functions). Please reduce the length of the messages or functions.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
During task with name 'researcher' and id '6e7de72c-7c3c-9ace-85c0-b40023ef870d'

2025-09-08 22:32:12,006 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:32:15,434 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:32:15,434 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:32:15,440 - __main__ - INFO - 
Test Input:
2025-09-08 22:32:15,440 - __main__ - INFO - - From: Barcelona
2025-09-08 22:32:15,440 - __main__ - INFO - - To: Paris
2025-09-08 22:32:15,441 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:32:15,441 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:32:15,441 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:32:28,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:32:30,396 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:32:38,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-08 22:32:38,864 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 242, in run_vacation_graph
    for chunk in graph.stream(initial_state):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\main.py", line 2647, in stream
    for _ in runner.tick(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 388, in researcher_node
    result = agent_executor.invoke(agent_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 573, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 1044, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1131, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1256, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 175124 tokens (175003 in the messages, 121 in the functions). Please reduce the length of the messages or functions.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
During task with name 'researcher' and id '50796c2e-7533-365c-32cb-ffef145b53fa'

2025-09-08 22:33:56,322 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:34:06,534 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:34:06,535 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:34:06,552 - __main__ - INFO - 
Test Input:
2025-09-08 22:34:06,552 - __main__ - INFO - - From: Barcelona
2025-09-08 22:34:06,552 - __main__ - INFO - - To: Paris
2025-09-08 22:34:06,553 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:34:06,553 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:34:06,553 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:34:19,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:34:22,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:34:30,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-08 22:34:30,454 - openai._base_client - INFO - Retrying request to /chat/completions in 0.394346 seconds
2025-09-08 22:34:32,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-08 22:34:32,316 - openai._base_client - INFO - Retrying request to /chat/completions in 0.977773 seconds
2025-09-08 22:34:34,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-08 22:34:34,380 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 242, in run_vacation_graph
    for chunk in graph.stream(initial_state):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\main.py", line 2647, in stream
    for _ in runner.tick(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 388, in researcher_node
    result = agent_executor.invoke(agent_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\chains\base.py", line 165, in invoke
    self._call(inputs, run_manager=run_manager)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1625, in _call
    next_step_output = self._take_next_step(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1325, in _take_next_step
    list(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 1352, in _iter_next_step
    output = self._action_agent.plan(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\agent.py", line 573, in plan
    for chunk in self.runnable.stream(inputs, config={"callbacks": callbacks}):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3437, in stream
    yield from self.transform(iter([input]), config, **kwargs)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3423, in transform
    yield from self._transform_stream_with_config(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 2214, in _transform_stream_with_config
    chunk: Output = context.run(next, iterator)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3385, in _transform
    yield from final_pipeline
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1428, in transform
    for ichunk in input:
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5650, in transform
    yield from self.bound.transform(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1446, in transform
    yield from self.stream(final, config, **kwargs)
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 522, in stream
    for chunk in self._stream(input_messages, stop=stop, **kwargs):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 1044, in _stream
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1131, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1256, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-GO3KEt0dk15BJ8o7bPiHesVt on tokens per min (TPM): Limit 30000, Requested 127310. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
During task with name 'researcher' and id '1dc69759-714b-7ae8-3c1a-3270f467d2f0'

2025-09-08 22:36:28,430 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:36:35,811 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:36:35,811 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:36:35,819 - __main__ - INFO - 
Test Input:
2025-09-08 22:36:35,820 - __main__ - INFO - - From: Barcelona
2025-09-08 22:36:35,820 - __main__ - INFO - - To: Paris
2025-09-08 22:36:35,820 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:36:35,820 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:36:35,821 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:36:35,845 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 227, in run_vacation_graph
    graph = build_vacation_graph(vacation_config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\graphs\VacayMate_graph.py", line 57, in build_vacation_graph
    manager_node = make_manager_node(llm_model=config["agents"][MANAGER]["llm"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 10, in make_manager_node
    llm = get_llm(llm_model)
          ^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\llm.py", line 18, in get_llm
    raise ValueError(f"Unknown model name: {model_name}")
ValueError: Unknown model name: gpt-3.5-turbo

2025-09-08 22:37:06,288 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:37:09,392 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:37:09,392 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:37:09,396 - __main__ - INFO - 
Test Input:
2025-09-08 22:37:09,397 - __main__ - INFO - - From: Barcelona
2025-09-08 22:37:09,397 - __main__ - INFO - - To: Paris
2025-09-08 22:37:09,397 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:37:09,398 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:37:09,398 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:37:09,420 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 227, in run_vacation_graph
    graph = build_vacation_graph(vacation_config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\graphs\VacayMate_graph.py", line 57, in build_vacation_graph
    manager_node = make_manager_node(llm_model=config["agents"][MANAGER]["llm"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 10, in make_manager_node
    llm = get_llm(llm_model)
          ^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\llm.py", line 18, in get_llm
    raise ValueError(f"Unknown model name: {model_name}")
ValueError: Unknown model name: gpt-3.5-turbo

2025-09-08 22:37:50,442 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:37:53,179 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:37:53,179 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:37:53,187 - __main__ - INFO - 
Test Input:
2025-09-08 22:37:53,187 - __main__ - INFO - - From: Barcelona
2025-09-08 22:37:53,188 - __main__ - INFO - - To: Paris
2025-09-08 22:37:53,188 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:37:53,188 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:37:53,189 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:37:53,208 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 227, in run_vacation_graph
    graph = build_vacation_graph(vacation_config)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\graphs\VacayMate_graph.py", line 57, in build_vacation_graph
    manager_node = make_manager_node(llm_model=config["agents"][MANAGER]["llm"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 10, in make_manager_node
    llm = get_llm(llm_model)
          ^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\llm.py", line 18, in get_llm
    raise ValueError(f"Unknown model name: {model_name}")
ValueError: Unknown model name: gpt-3.5-turbo-0125

2025-09-08 22:38:18,093 - __main__ - INFO - Attempting to import run_vacation_graph...
2025-09-08 22:38:20,944 - __main__ - INFO - Successfully imported VacayMate_system
2025-09-08 22:38:20,944 - __main__ - INFO - Successfully imported run_vacation_graph
2025-09-08 22:38:20,948 - __main__ - INFO - 
Test Input:
2025-09-08 22:38:20,948 - __main__ - INFO - - From: Barcelona
2025-09-08 22:38:20,948 - __main__ - INFO - - To: Paris
2025-09-08 22:38:20,949 - __main__ - INFO - - Dates: 2025-09-22 to 2025-09-29
2025-09-08 22:38:20,949 - __main__ - INFO - 
Running the vacation planner...

2025-09-08 22:38:20,949 - __main__ - INFO - Calling run_vacation_graph...
2025-09-08 22:38:32,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-08 22:38:34,202 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\test_vacaymate.py", line 64, in <module>
    result = run_vacation_graph(test_input)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\VacayMate_system.py", line 242, in run_vacation_graph
    for chunk in graph.stream(initial_state):
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\main.py", line 2647, in stream
    for _ in runner.tick(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_runner.py", line 162, in tick
    run_with_retry(
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\_internal\_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\Documents\Ready_Tensor_AI_Course\course_workspace\VacayMate\code\nodes\VacayMate_nodes.py", line 356, in researcher_node
    agent = create_tool_calling_agent(llm, tools, prompt)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\agents\tool_calling_agent\base.py", line 101, in create_tool_calling_agent
    llm_with_tools = llm.bind_tools(tools)
                     ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 1652, in bind_tools
    convert_to_openai_tool(tool, strict=strict) for tool in tools
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\function_calling.py", line 584, in convert_to_openai_tool
    oai_function = convert_to_openai_function(tool, strict=strict)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\97254\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\function_calling.py", line 486, in convert_to_openai_function
    raise ValueError(msg)
ValueError: Unsupported function

bound=StructuredTool(name='search_hotels', description='Search for hotels in a specific location and date range.', args_schema=<class 'langchain_core.utils.pydantic.search_hotels'>, func=<function make_researcher_node.<locals>.researcher_node.<locals>.search_hotels at 0x0000021910C80A40>) kwargs={'max_results': 3} config={} config_factories=[]

Functions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys.
During task with name 'researcher' and id '8c8aa25a-a81f-4379-c214-3a3370720d10'

